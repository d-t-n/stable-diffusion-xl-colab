{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPZ-pX634e7S"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufD_d64nr08H"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "%pip install --quiet --upgrade diffusers transformers accelerate invisible_watermark mediapy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRVsA7iYxpMj"
      },
      "outputs": [],
      "source": [
        "# Flag to determine whether to use the refiner model\n",
        "use_refiner = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzkvjD6j4e7Y"
      },
      "source": [
        "# Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG2hkmSEvByV"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import mediapy as media\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# Import the DiffusionPipeline from diffusers\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "# Initialize the DiffusionPipeline with a pre-trained base model\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        ")\n",
        "\n",
        "# Check if using refiner\n",
        "if use_refiner:\n",
        "    # Initialize a DiffusionPipeline with a pre-trained refiner model\n",
        "    refiner = DiffusionPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "        text_encoder_2=pipe.text_encoder_2,\n",
        "        vae=pipe.vae,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        variant=\"fp16\",\n",
        "    )\n",
        "\n",
        "    # Move the refiner model to CUDA (GPU)\n",
        "    refiner = refiner.to(\"cuda\")\n",
        "\n",
        "    # Enable model CPU offload for the base pipeline\n",
        "    pipe.enable_model_cpu_offload()\n",
        "else:\n",
        "    # Move the base pipeline to CUDA (GPU)\n",
        "    pipe = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUc4QJfE-uR9"
      },
      "outputs": [],
      "source": [
        "# Specify a prompt for image generation\n",
        "#prompt = \"abstract colors, texture, film grain:0. 1 intricate close up dramatic portrait of a (cyberpunk)1. 2 porsche standing on a rainy bustling crowded cyberpunk city street, ultra realistic texture, foggy morning, cinematic movie still frame, gtr, altered carbon, (analog style)1. 3 (film grain)1. 3, stephan martiniere Wadim Kashin Simon Stalenhag michal karcz ismail inceoglu\"\n",
        "prompt = \"an outdoor sculpture of a head using discarded car parts, highlighting it's beauty, highly detailed, 8k\"\n",
        "# Generate a random seed\n",
        "seed = random.randint(0, sys.maxsize)\n",
        "\n",
        "# Use the pipeline to generate images based on the prompt\n",
        "images = pipe(\n",
        "    prompt=prompt,\n",
        "    output_type=\"latent\" if use_refiner else \"pil\",\n",
        "    generator=torch.Generator(\"cuda\").manual_seed(seed),\n",
        ").images\n",
        "\n",
        "# If using the refiner, refine the images\n",
        "if use_refiner:\n",
        "    images = refiner(\n",
        "        prompt=prompt,\n",
        "        image=images,\n",
        "    ).images\n",
        "\n",
        "# Print the prompt and seed\n",
        "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
        "\n",
        "# Display the generated images\n",
        "media.show_images(images)\n",
        "\n",
        "# Save the first image as \"output.jpg\"\n",
        "images[0].save(\"output.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMMdGbWm5Wpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "stable-diffusion.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}